{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3bc98ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\monish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\monish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.3\n"
     ]
    }
   ],
   "source": [
    "# Import libraries - Python 3.8\n",
    "import os\n",
    "import numpy as np\n",
    "import gensim\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "import sklearn.preprocessing as pp\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Concatenate, Input, InputLayer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow import one_hot\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "join = os.path.join\n",
    "\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c6c7b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries - Python 3.6\n",
    "import fasttext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "join = os.path.join\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d2dc475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284125b1",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfb61888",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"../final\"\n",
    "# root_path = \"./../data/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6696da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files\n",
    "\n",
    "video1_csv = \"baseline1_final.csv\"\n",
    "df_video1 = pd.read_csv(join(root_path, video1_csv), sep='\\t')\n",
    "\n",
    "channel_csv = \"baseline_final_channels.csv\"\n",
    "df_channel = pd.read_csv(join(root_path, channel_csv), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45c250e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2120, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it happened outside waco texas a heavily armed...</td>\n",
       "      <td>the shadow of waco  retro report  the new york...</td>\n",
       "      <td>0</td>\n",
       "      <td>hOW9AjskoOo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thanks for coming its nice to see a good turno...</td>\n",
       "      <td>former abortionist dr levatino destroys procho...</td>\n",
       "      <td>0</td>\n",
       "      <td>dIRcw45n9RU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tonight  i donald john trump do solemnly swear...</td>\n",
       "      <td>trumps road to the white house full film  fron...</td>\n",
       "      <td>0</td>\n",
       "      <td>SMwXKl0odq8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this week on buzzfeed unsolved we discuss the...</td>\n",
       "      <td>the strange disappearance of db cooper</td>\n",
       "      <td>0</td>\n",
       "      <td>oHSehKtDyoI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im mason noise im 22 and im from birmingham wh...</td>\n",
       "      <td>shockingly offensive auditions have simon cowe...</td>\n",
       "      <td>0</td>\n",
       "      <td>N9COy7O7K-U</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             caption  \\\n",
       "0  it happened outside waco texas a heavily armed...   \n",
       "1  thanks for coming its nice to see a good turno...   \n",
       "2  tonight  i donald john trump do solemnly swear...   \n",
       "3   this week on buzzfeed unsolved we discuss the...   \n",
       "4  im mason noise im 22 and im from birmingham wh...   \n",
       "\n",
       "                                               title  label     video_id  \n",
       "0  the shadow of waco  retro report  the new york...      0  hOW9AjskoOo  \n",
       "1  former abortionist dr levatino destroys procho...      0  dIRcw45n9RU  \n",
       "2  trumps road to the white house full film  fron...      0  SMwXKl0odq8  \n",
       "3             the strange disappearance of db cooper      0  oHSehKtDyoI  \n",
       "4  shockingly offensive auditions have simon cowe...      0  N9COy7O7K-U  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_video1.shape)\n",
    "df_video1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6981ac98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(884, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_id</th>\n",
       "      <th>video_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCqnbDFdCpuN8CMEg0VuEBqA</td>\n",
       "      <td>hOW9AjskoOo,uJ44spUo8Uk,-O_DMyHdq_M,U_hbIPJuia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCfkzsfj7Go1Q_kRFZmJptsw</td>\n",
       "      <td>dIRcw45n9RU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UC3ScyryU9Oy9Wse3a8OAmYQ</td>\n",
       "      <td>SMwXKl0odq8,AW0gsP3EgDI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCKijjvu6bN1c-ZHVwR7-5WA</td>\n",
       "      <td>oHSehKtDyoI,lDeFSOUHdH4,cDZweMXXY6Y,p2EUZ-gwe6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UC6my_lD3kBECBifeq0n2mdg</td>\n",
       "      <td>N9COy7O7K-U,DHwpwD-ae7I,74fTHh6jB5Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 channel_id                                          video_ids\n",
       "0  UCqnbDFdCpuN8CMEg0VuEBqA  hOW9AjskoOo,uJ44spUo8Uk,-O_DMyHdq_M,U_hbIPJuia...\n",
       "1  UCfkzsfj7Go1Q_kRFZmJptsw                                        dIRcw45n9RU\n",
       "2  UC3ScyryU9Oy9Wse3a8OAmYQ                            SMwXKl0odq8,AW0gsP3EgDI\n",
       "3  UCKijjvu6bN1c-ZHVwR7-5WA  oHSehKtDyoI,lDeFSOUHdH4,cDZweMXXY6Y,p2EUZ-gwe6...\n",
       "4  UC6my_lD3kBECBifeq0n2mdg                N9COy7O7K-U,DHwpwD-ae7I,74fTHh6jB5Q"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_channel.shape)\n",
    "df_channel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c39874ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HARDCODED limits per topic for baseline1 dataset\n",
    "TOPIC_LIMITS = [0, 430, 901, 1214, 1530, 2120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5aefebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "captions1_list = df_video1[\"caption\"].to_list()\n",
    "video1_list = df_video1[\"video_id\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "160bbe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to 2-class\n",
    "df_video1[\"label\"].replace(-1, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b92f4a5",
   "metadata": {},
   "source": [
    "### Captions -> word2vec, extract embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c1304fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../final\\\\GoogleNews-vectors-negative300.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12620/1774952539.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load word2vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mword2vec_300\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"GoogleNews-vectors-negative300.bin\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mword2vec_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword2vec_300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mword2vec_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[0;32m   1545\u001b[0m         \"\"\"\n\u001b[0;32m   1546\u001b[0m         \u001b[1;31m# from gensim.models.word2vec import load_word2vec_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1547\u001b[1;33m         return _load_word2vec_format(\n\u001b[0m\u001b[0;32m   1548\u001b[0m             \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1549\u001b[0m             limit=limit, datatype=datatype)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, binary_chunk_size)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loading projection weights from %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m         \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# throws for invalid file format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[0mtransport_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m     fobj = _shortcut_open(\n\u001b[0m\u001b[0;32m    303\u001b[0m         \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[1;34m(uri, mode, ignore_ext, buffering, encoding, errors)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mopen_kwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../final\\\\GoogleNews-vectors-negative300.bin'"
     ]
    }
   ],
   "source": [
    "# Load word2vec\n",
    "word2vec_300 = \"GoogleNews-vectors-negative300.bin\"\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(join(root_path, word2vec_300), binary = True)\n",
    "word2vec_model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe751bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(word2vec_model, doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    doc = [word for word in doc if word in word2vec_model.vocab]\n",
    "    return np.mean(word2vec_model[doc], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefbdff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our earlier preprocessing was done when we were dealing only with word vectors\n",
    "# Here, we need each document to remain a document \n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    doc = word_tokenize(text)\n",
    "    doc = [word for word in doc if word.isalpha()] \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538a9140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that will help us drop documents that have no word vectors in word2vec\n",
    "def has_vector_representation(word2vec_model, doc):\n",
    "    \"\"\"check if at least one word of the document is in the\n",
    "    word2vec dictionary\"\"\"\n",
    "    return not all(word not in word2vec_model.vocab for word in doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7348ca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out documents\n",
    "def filter_docs(corpus, texts, video_ids, condition_on_doc):\n",
    "    \"\"\"\n",
    "    Filter corpus and texts given the function condition_on_doc which takes a doc. The document doc is kept if condition_on_doc(doc) is true.\n",
    "    \"\"\"\n",
    "    number_of_docs = len(corpus)\n",
    "\n",
    "    ret_texts, ret_videos = [], []\n",
    "    if texts is not None:\n",
    "        for (text, doc, video_id) in zip(texts, corpus, video_ids):\n",
    "            if condition_on_doc(doc):\n",
    "                ret_texts.append(text)\n",
    "                ret_videos.append(video_id)\n",
    "\n",
    "    corpus = [doc for doc in corpus if condition_on_doc(doc)]\n",
    "\n",
    "    print(\"{} docs removed\".format(number_of_docs - len(corpus)))\n",
    "\n",
    "    return (corpus, ret_texts, ret_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348d360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def captions_to_word2vec(caption_list, video_list, model):\n",
    "    # Preprocess the corpus\n",
    "    corpus = [preprocess(title) for title in caption_list]\n",
    "\n",
    "    # Remove docs that don't include any words in W2V's vocab\n",
    "    corpus, titles_list, video_list = filter_docs(corpus, caption_list, video_list, lambda doc: has_vector_representation(model, doc))\n",
    "\n",
    "    # Filter out any empty docs\n",
    "    corpus, titles_list, video_list = filter_docs(corpus, caption_list, video_list, lambda doc: (len(doc) != 0))\n",
    "    x = []\n",
    "    for doc in corpus: # append the vector for each document\n",
    "        x.append(document_vector(model, doc))\n",
    "\n",
    "    X = np.array(x) # list to array\n",
    "    \n",
    "    return X, video_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccda93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "captions1_X, cap_w2v_videos = captions_to_word2vec(captions1_list, video1_list, word2vec_model)\n",
    "captions1_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77797ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "with open(join(root_path, 'baseline1_word2vec_300.npy'), 'wb') as f:\n",
    "    np.save(f, captions1_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "761dfab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "assert os.path.isfile(join(root_path, 'baseline1_word2vec_300.npy'))\n",
    "captions1_X = np.load(join(root_path, 'baseline1_word2vec_300.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0513815b",
   "metadata": {},
   "source": [
    "### Captions -> fastText\n",
    "Source: https://github.com/kostantinos-papadamou/pseudoscience-paper\n",
    "Use Python 3.6 to run the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "82cd6eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat data, save to file\n",
    "with open(join(root_path, 'fasttext_captions.txt'), 'w') as f:\n",
    "    for item in captions1_list:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ef16199e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "../final\\wiki-news-300d-1M.vec cannot be opened for loading!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24904/2731007022.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fine tune fasttext model, save to file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfasttext_models_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'fasttext_model_finetuned.bin'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m ft_model = fasttext.train_unsupervised(\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fasttext_captions.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpretrainedVectors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wiki-news-300d-1M.vec'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\fasttext\\FastText.py\u001b[0m in \u001b[0;36mtrain_unsupervised\u001b[1;34m(*kargs, **kwargs)\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_build_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmanually_set_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m     \u001b[0mft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FastText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m     \u001b[0mfasttext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m     \u001b[0mft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetArgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mft\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: ../final\\wiki-news-300d-1M.vec cannot be opened for loading!"
     ]
    }
   ],
   "source": [
    "# Fine tune fasttext model, save to file\n",
    "fasttext_models_filename = 'fasttext_model_finetuned.bin'\n",
    "ft_model = fasttext.train_unsupervised(\n",
    "    input=join(root_path, 'fasttext_captions.txt'),\n",
    "    pretrainedVectors=join(root_path, 'wiki-news-300d-1M.vec'),\n",
    "    dim=300,\n",
    "    minn=2,\n",
    "    maxn=5,\n",
    "    verbose=2)\n",
    "ft_model.save_model(join(root_path, fasttext_models_filename))\n",
    "del ft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8ba9ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2120, 300)\n"
     ]
    }
   ],
   "source": [
    "# Get caption features\n",
    "ft_model = fasttext.load_model(join(root_path, \"fasttext_model_finetuned-002.bin\"))\n",
    "ft_features = []\n",
    "for caption in captions1_list:\n",
    "    ft_features += [ft_model.get_sentence_vector(text=caption)]\n",
    "ft_features = np.array(ft_features)\n",
    "print(ft_features.shape)\n",
    "del ft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a79da6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save to file\n",
    "# with open(join(root_path, 'baseline1_fasttext_300.npy'), 'wb') as f:\n",
    "#     np.save(f, ft_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc798ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "assert os.path.isfile(join(root_path, 'baseline1_fasttext_300.npy'))\n",
    "ft_features = np.load(join(root_path, 'baseline1_fasttext_300.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f8765e",
   "metadata": {},
   "source": [
    "### Train deep learning model on fastText, extract embeddings\n",
    "Source: https://github.com/kostantinos-papadamou/pseudoscience-paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b4222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify GPU environment\n",
    "gpu_training = True\n",
    "if gpu_training:\n",
    "    # Train on GPU\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "else:\n",
    "    # Train on CPU\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d32559d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2120,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve labels\n",
    "ft_labels = df_video1[\"label\"].to_numpy()\n",
    "ft_labels[ft_labels == -1] = 0  # make two class\n",
    "ft_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79da9349",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " fully_connected_1 (Dense)   (None, 256)               77056     \n",
      "                                                                 \n",
      " dropout_layer_1 (Dropout)   (None, 256)               0         \n",
      "                                                                 \n",
      " fully_connected_2 (Dense)   (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_layer_2 (Dropout)   (None, 128)               0         \n",
      "                                                                 \n",
      " fully_connected_3 (Dense)   (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_layer_3 (Dropout)   (None, 64)                0         \n",
      "                                                                 \n",
      " fully_connected_4 (Dense)   (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_layer_4 (Dropout)   (None, 32)                0         \n",
      "                                                                 \n",
      " classification_layer (Dense  (None, 2)                66        \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120,354\n",
      "Trainable params: 120,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ericm/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "class PsuedoscienceDeepLearningModel(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Initialize hyperparameters\n",
    "        self.embedding_dim = 300\n",
    "        self.dropout = 0.5\n",
    "        self.learning_rate = 1e-3\n",
    "        self.val_split_size = 0.2\n",
    "        self.num_epochs = 100\n",
    "        self.num_folds = 10  # for k-fold cross validation\n",
    "        self.batch_size = 20\n",
    "        self.shuffle_train_set = True\n",
    "        self.oversampling = True\n",
    "        self.num_classes = 2\n",
    "        \n",
    "        self.model = self.build_model()\n",
    "    \n",
    "    def build_model(self):\n",
    "        seq = Sequential()\n",
    "        seq.add(Dense(units=256, activation='relu', name='fully_connected_1', input_shape=(self.embedding_dim,)))\n",
    "        seq.add(Dropout(rate=self.dropout, name='dropout_layer_1'))\n",
    "        seq.add(Dense(units=128, activation='relu', name='fully_connected_2'))\n",
    "        seq.add(Dropout(rate=self.dropout, name='dropout_layer_2'))\n",
    "        seq.add(Dense(units=64, activation='relu', name='fully_connected_3'))\n",
    "        seq.add(Dropout(rate=self.dropout, name='dropout_layer_3'))\n",
    "        seq.add(Dense(units=32, activation='relu', name='fully_connected_4'))\n",
    "        seq.add(Dropout(rate=self.dropout, name='dropout_layer_4'))\n",
    "        seq.add(Dense(units=self.num_classes, activation='softmax', name='classification_layer'))\n",
    "        seq.compile(loss=BinaryCrossentropy(from_logits=False),\n",
    "                    optimizer=Adam(lr=self.learning_rate),\n",
    "                    metrics=[F1Score(num_classes=2)])\n",
    "        return seq\n",
    "    \n",
    "    def summary(self):\n",
    "        return self.model.summary()\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "\n",
    "model = PsuedoscienceDeepLearningModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc79476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               verbose=2,\n",
    "                               mode='auto',\n",
    "                               restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "796ea3b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ft_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24904/1568781314.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/n---Training the Model with {} videos.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mft_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[0;32m      5\u001b[0m     ft_features, ft_labels, test_size=model.val_split_size)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ft_features' is not defined"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "print('/n---Training the Model with {} videos.'.format(ft_features.shape[0]))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    ft_features, ft_labels, test_size=model.val_split_size)\n",
    "\n",
    "# Oversampling\n",
    "if model.oversampling:\n",
    "    smote = SMOTE(sampling_strategy='not majority')\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    print('--- [AFTER OVER-SAMPLING] TRAIN: %d' % (y_train.shape[0]))\n",
    "\n",
    "# Convert labels to 1-hot\n",
    "y_train = one_hot(y_train, model.num_classes)\n",
    "y_test = one_hot(y_test, model.num_classes)\n",
    "\n",
    "# Train the model\n",
    "model_train_input = [X_train]\n",
    "model_val_input = [X_test]\n",
    "m = model.get_model()\n",
    "m.fit(model_train_input,\n",
    "      y_train,\n",
    "      epochs=model.num_epochs,\n",
    "      batch_size=model.batch_size,\n",
    "      validation_data=[model_val_input, y_test],\n",
    "      shuffle=model.shuffle_train_set,\n",
    "      verbose=1,\n",
    "      callbacks=[early_stopping])\n",
    "\n",
    "# Save trained model\n",
    "m.save(join(root_path, 'nn.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c372305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model = load_model(join(root_path, \"nn_75.hdf5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c125a4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2120, 32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve layer outputs\n",
    "layer_name = 'fully_connected_4'\n",
    "intermediate_model = Model(inputs=best_model.input,\n",
    "                          outputs=best_model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_model.predict(ft_features)\n",
    "intermediate_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d911e0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97559605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "assert os.path.isfile(join(root_path, 'baseline1_nn_32.npy'))\n",
    "intermediate_output = np.load(join(root_path, 'baseline1_nn_32.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba9f1f9",
   "metadata": {},
   "source": [
    "### Load embeddings from our approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d9aba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_novel = np.load(join(root_path, 'bi_embedding.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "758244e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert from ragged tensor to normal numpy array\n",
    "# X_novel = np.zeros((ce.shape[0], ce[0][0].shape[0]))\n",
    "# for i in range(ce.shape[0]):\n",
    "#     X_novel[i, :] = ce[i][0]\n",
    "# X_novel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5a5fef",
   "metadata": {},
   "source": [
    "### Normalize CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8de2fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X_novel.shape[0]):\n",
    "    X_novel[i] = X_novel[i] / np.linalg.norm(X_novel[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41e52425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00104776, -0.00723376,  0.01471311],\n",
       "       [-0.00116783, -0.00725456,  0.01445016],\n",
       "       [-0.00166335, -0.00807987,  0.01418412]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_novel[:3, :3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69ee9c9",
   "metadata": {},
   "source": [
    "### Compute similarity between channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75e0e741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarities(mat):\n",
    "    col_normed_mat = pp.normalize(coo_matrix(mat.T).tocsc(), axis=0)\n",
    "    return col_normed_mat.T * col_normed_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f10be18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ground_truth_diff_for_channels(baseline_final, baseline_channels):\n",
    "    \n",
    "    num_channels = len(baseline_channels)\n",
    "    channel_ground_truth_proportion = np.empty(num_channels, dtype='float32')\n",
    "\n",
    "    for index, row in baseline_channels.iterrows():\n",
    "        videos = row['video_ids'].split(',')\n",
    "\n",
    "        channel_videos = baseline_final[baseline_final[\"video_id\"].isin(videos)]\n",
    "        proportion = np.mean(channel_videos[\"label\"].to_numpy())\n",
    "        channel_ground_truth_proportion[index] = proportion\n",
    "    \n",
    "    return channel_ground_truth_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd97424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ground_truth_diff(p):\n",
    "    return np.abs(p[:, np.newaxis] - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4614c1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(884, 884)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute ground truth proportion differences for channels\n",
    "misinfo_proportions = compute_ground_truth_diff_for_channels(df_video1, df_channel)\n",
    "proportion_diffs = compute_ground_truth_diff(misinfo_proportions)\n",
    "proportion_diffs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab3a91e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_channel_embeddings(df_video, df_channel, video_embeddings):\n",
    "    \n",
    "    num_channels = len(df_channel)\n",
    "    embedding_size = video_embeddings.shape[1]\n",
    "    channel_embeddings = np.empty((num_channels, embedding_size), dtype='float32')\n",
    "    \n",
    "    for index, row in df_channel.iterrows():\n",
    "        videos = row['video_ids'].split(',')\n",
    "        \n",
    "        video_i = df_video.index[df_video[\"video_id\"].isin(videos)]\n",
    "        channel_embeddings[index, :] = np.mean(video_embeddings[video_i, :], axis=0)\n",
    "    \n",
    "    return channel_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0782351f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((884, 300), (884, 32), (884, 768))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute channel embeddings for baselines\n",
    "word2vec_channel_emb = compute_channel_embeddings(df_video1, df_channel, captions1_X)\n",
    "nn_channel_emb = compute_channel_embeddings(df_video1, df_channel, intermediate_output)\n",
    "novel_channel_emb = compute_channel_embeddings(df_video1, df_channel, X_novel)\n",
    "word2vec_channel_emb.shape, nn_channel_emb.shape, novel_channel_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be9d990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((884, 884), (884, 884), (884, 884))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cosine similarities\n",
    "word2vec_channel_sim = cosine_similarities(word2vec_channel_emb).toarray()\n",
    "nn_channel_sim = cosine_similarities(nn_channel_emb).toarray()\n",
    "novel_channel_sim = cosine_similarities(novel_channel_emb).toarray()\n",
    "word2vec_channel_sim.shape, nn_channel_sim.shape, novel_channel_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e349cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09198472 1.0\n",
      "0.0 1.0\n",
      "0.94883376 1.0\n"
     ]
    }
   ],
   "source": [
    "# All cosine similarities must be between 0 and 1\n",
    "\n",
    "word2vec_channel_sim[word2vec_channel_sim > 1.0] = 1.0\n",
    "word2vec_channel_sim[word2vec_channel_sim < 0.0] = 0.0\n",
    "nn_channel_sim[nn_channel_sim > 1.0] = 1.0\n",
    "nn_channel_sim[nn_channel_sim < 0.0] = 0.0\n",
    "novel_channel_sim[novel_channel_sim > 1.0] = 1.0\n",
    "novel_channel_sim[novel_channel_sim < 0.0] = 0.0\n",
    "\n",
    "print(word2vec_channel_sim.min(), word2vec_channel_sim.max())\n",
    "print(nn_channel_sim.min(), nn_channel_sim.max())\n",
    "print(novel_channel_sim.min(), novel_channel_sim.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0f8d9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 37, 125)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter channels according to number of videos\n",
    "# A minimum of 3 is required for fair comparison\n",
    "filtered_indices = []\n",
    "filtered_misinfo_indices = []\n",
    "filtered_nonmisinfo_indices = []\n",
    "for index, row in df_channel.iterrows():\n",
    "    videos = row['video_ids'].split(',')\n",
    "    if len(videos) >= 3:\n",
    "        filtered_indices += [index]\n",
    "        \n",
    "        channel_videos = df_video1[df_video1[\"video_id\"].isin(videos)]\n",
    "        if (channel_videos['label'] == 1).sum() > 0:\n",
    "            filtered_misinfo_indices += [index]\n",
    "        else:\n",
    "            filtered_nonmisinfo_indices += [index]\n",
    "\n",
    "len(filtered_indices), len(filtered_misinfo_indices), len(filtered_nonmisinfo_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f346e0f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word2vec_channel_sim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12620/2571715263.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpd_misinfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproportion_diffs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfiltered_misinfo_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_misinfo_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpd_nonmisinfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproportion_diffs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfiltered_nonmisinfo_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_nonmisinfo_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mw2v_sim_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword2vec_channel_sim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfiltered_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mw2v_sim_misinfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword2vec_channel_sim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfiltered_misinfo_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_misinfo_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mw2v_sim_nonmisinfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword2vec_channel_sim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfiltered_nonmisinfo_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_nonmisinfo_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word2vec_channel_sim' is not defined"
     ]
    }
   ],
   "source": [
    "# Filter proportion diff and similarity matrices accordingly\n",
    "pd_all = proportion_diffs[filtered_indices, :][:, filtered_indices]\n",
    "pd_misinfo = proportion_diffs[filtered_misinfo_indices, :][:, filtered_misinfo_indices]\n",
    "pd_nonmisinfo = proportion_diffs[filtered_nonmisinfo_indices, :][:, filtered_nonmisinfo_indices]\n",
    "w2v_sim_all = word2vec_channel_sim[filtered_indices, :][:, filtered_indices]\n",
    "w2v_sim_misinfo = word2vec_channel_sim[filtered_misinfo_indices, :][:, filtered_misinfo_indices]\n",
    "w2v_sim_nonmisinfo = word2vec_channel_sim[filtered_nonmisinfo_indices, :][:, filtered_nonmisinfo_indices]\n",
    "nn_sim_all = nn_channel_sim[filtered_indices, :][:, filtered_indices]\n",
    "nn_sim_misinfo = nn_channel_sim[filtered_misinfo_indices, :][:, filtered_misinfo_indices]\n",
    "nn_sim_nonmisinfo = nn_channel_sim[filtered_nonmisinfo_indices, :][:, filtered_nonmisinfo_indices]\n",
    "novel_sim_all = novel_channel_sim[filtered_indices, :][:, filtered_indices]\n",
    "novel_sim_misinfo = novel_channel_sim[filtered_misinfo_indices, :][:, filtered_misinfo_indices]\n",
    "novel_sim_nonmisinfo = novel_channel_sim[filtered_nonmisinfo_indices, :][:, filtered_nonmisinfo_indices]\n",
    "pd_all.shape, pd_misinfo.shape, pd_nonmisinfo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a6c22d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract upper diagonals as flat matrix\n",
    "\n",
    "ind_all = np.triu_indices(len(filtered_indices), k=1)\n",
    "ind_misinfo = np.triu_indices(len(filtered_misinfo_indices), k=1)\n",
    "ind_nonmisinfo = np.triu_indices(len(filtered_nonmisinfo_indices), k=1)\n",
    "pd_all_ud = pd_all[ind_all]\n",
    "pd_misinfo_ud = pd_misinfo[ind_misinfo]\n",
    "pd_nonmisinfo_ud = pd_nonmisinfo[ind_nonmisinfo]\n",
    "\n",
    "pd_both = proportion_diffs[filtered_misinfo_indices, :][:, filtered_nonmisinfo_indices]\n",
    "pd_both_ud = pd_both.flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3928d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_all_ud = pd_all[ind_all]\n",
    "pd_misinfo_ud = pd_misinfo[ind_misinfo]\n",
    "pd_nonmisinfo_ud = pd_nonmisinfo[ind_nonmisinfo]\n",
    "\n",
    "w2v_sim_all_ud = w2v_sim_all[ind_all]\n",
    "w2v_sim_misinfo_ud = w2v_sim_misinfo[ind_misinfo]\n",
    "w2v_sim_nonmisinfo_ud = w2v_sim_nonmisinfo[ind_nonmisinfo]\n",
    "\n",
    "nn_sim_all_ud = nn_sim_all[ind_all]\n",
    "nn_sim_misinfo_ud = nn_sim_misinfo[ind_misinfo]\n",
    "nn_sim_nonmisinfo_ud = nn_sim_nonmisinfo[ind_nonmisinfo]\n",
    "\n",
    "novel_sim_all_ud = novel_sim_all[ind_all]\n",
    "novel_sim_misinfo_ud = novel_sim_misinfo[ind_misinfo]\n",
    "novel_sim_nonmisinfo_ud = novel_sim_nonmisinfo[ind_nonmisinfo]\n",
    "\n",
    "pd_all_ud.shape, pd_misinfo_ud.shape, pd_nonmisinfo_ud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16c5c3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4625,), (4625,), (4625,), (4625,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract cosine similarities of (misinfo, nonmisinfo) pairs\n",
    "# This needs to be done separately as it won't be a square matrix\n",
    "\n",
    "pd_both = proportion_diffs[filtered_misinfo_indices, :][:, filtered_nonmisinfo_indices]\n",
    "w2v_sim_both = word2vec_channel_sim[filtered_misinfo_indices, :][:, filtered_nonmisinfo_indices]\n",
    "nn_sim_both = nn_channel_sim[filtered_misinfo_indices, :][:, filtered_nonmisinfo_indices]\n",
    "novel_sim_both = novel_channel_sim[filtered_misinfo_indices, :][:, filtered_nonmisinfo_indices]\n",
    "\n",
    "# Naming convention: _ud to be similar to other variables\n",
    "# No actual upper triangular calculation here\n",
    "pd_both_ud = pd_both.flatten()\n",
    "w2v_sim_both_ud = w2v_sim_both.flatten()\n",
    "nn_sim_both_ud = nn_sim_both.flatten()\n",
    "novel_sim_both_ud = novel_sim_both.flatten()\n",
    "\n",
    "pd_both_ud.shape, w2v_sim_both_ud.shape, nn_sim_both_ud.shape, novel_sim_both_ud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "004423b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_analysis_by_range(proportion_diffs_ud, sim_ud):\n",
    "\n",
    "    ranges = [(0.0, 0.2), (0.2, 0.4), (0.4, 0.6), (0.6, 0.8), (0.8, 1.01)]\n",
    "    for begin, end in ranges:\n",
    "\n",
    "        ind = np.argwhere((proportion_diffs_ud >= begin) & (proportion_diffs_ud < end))\n",
    "        \n",
    "        if ind.shape[0] > 0:\n",
    "            #proportion_diffs_i = proportion_diffs_ud[ind]\n",
    "            sim_i = sim_ud[ind]\n",
    "\n",
    "            print(\"For range\", begin, \"to\", end, \" - \", sim_i.shape[0], \"pairs\")\n",
    "            #print(\"25th percentile =\", np.percentile(sim_i, 25))\n",
    "            #print(\"50th percentile =\", np.percentile(sim_i, 50))\n",
    "            #print(\"75th percentile =\", np.percentile(sim_i, 75))\n",
    "            print(\"{0},{1},{2}\".format(np.percentile(sim_i, 25), np.percentile(sim_i, 50), np.percentile(sim_i, 75)))\n",
    "        else:\n",
    "            print(\"No pairs for range\", begin, \"to\", end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b4a01d",
   "metadata": {},
   "source": [
    "#### Results: any label to any label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4a8bc29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For range 0.0 to 0.2  -  9133 pairs\n",
      "0.9259091019630432,0.9569250345230103,0.9747517108917236\n",
      "For range 0.2 to 0.4  -  1750 pairs\n",
      "0.9337780624628067,0.9588366746902466,0.973519578576088\n",
      "For range 0.4 to 0.6  -  271 pairs\n",
      "0.9456446170806885,0.9669362306594849,0.9810445010662079\n",
      "For range 0.6 to 0.8  -  1214 pairs\n",
      "0.9366919100284576,0.9611344337463379,0.9744926393032074\n",
      "For range 0.8 to 1.01  -  673 pairs\n",
      "0.9479347467422485,0.9659979343414307,0.9776875376701355\n"
     ]
    }
   ],
   "source": [
    "result_analysis_by_range(pd_all_ud, w2v_sim_all_ud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e9c0ddb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For range 0.0 to 0.2  -  9133 pairs\n",
      "0.9773192405700684,0.9969475269317627,0.9994640350341797\n",
      "For range 0.2 to 0.4  -  1750 pairs\n",
      "0.5526943355798721,0.991633415222168,0.9985706955194473\n",
      "For range 0.4 to 0.6  -  271 pairs\n",
      "0.5335564315319061,0.5732368230819702,0.9283021092414856\n",
      "For range 0.6 to 0.8  -  1214 pairs\n",
      "0.07796964980661869,0.9157878458499908,0.9894870817661285\n",
      "For range 0.8 to 1.01  -  673 pairs\n",
      "0.008336368948221207,0.05354585871100426,0.3391764461994171\n"
     ]
    }
   ],
   "source": [
    "result_analysis_by_range(pd_all_ud, nn_sim_all_ud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e579aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For range 0.0 to 0.2  -  9133 pairs\n",
      "0.9989447593688965,0.9996557831764221,0.9999077916145325\n",
      "For range 0.2 to 0.4  -  1750 pairs\n",
      "0.9990879148244858,0.9997088611125946,0.9999207705259323\n",
      "For range 0.4 to 0.6  -  271 pairs\n",
      "0.9992295801639557,0.9997743964195251,0.9999341368675232\n",
      "For range 0.6 to 0.8  -  1214 pairs\n",
      "0.9990362375974655,0.9996720552444458,0.9999110102653503\n",
      "For range 0.8 to 1.01  -  673 pairs\n",
      "0.9991890788078308,0.9997066259384155,0.9999141693115234\n"
     ]
    }
   ],
   "source": [
    "result_analysis_by_range(pd_all_ud, novel_sim_all_ud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39a3992",
   "metadata": {},
   "source": [
    "#### Results: misinfo to misinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "801160b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For range 0.0 to 0.2  -  258 pairs\n",
      "0.9506474882364273,0.9678962230682373,0.9787565022706985\n",
      "For range 0.2 to 0.4  -  125 pairs\n",
      "0.9571177363395691,0.9734190702438354,0.9796338677406311\n",
      "For range 0.4 to 0.6  -  146 pairs\n",
      "0.9452119767665863,0.9641998410224915,0.9775935262441635\n",
      "For range 0.6 to 0.8  -  89 pairs\n",
      "0.9602387547492981,0.971376895904541,0.9801899194717407\n",
      "For range 0.8 to 1.01  -  48 pairs\n",
      "0.9673985242843628,0.9770538508892059,0.9858627766370773\n"
     ]
    }
   ],
   "source": [
    "result_analysis_by_range(pd_misinfo_ud, w2v_sim_misinfo_ud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39c1ba40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For range 0.0 to 0.2  -  258 pairs\n",
      "0.2811216786503792,0.9841984510421753,0.9979343265295029\n",
      "For range 0.2 to 0.4  -  125 pairs\n",
      "0.4025932252407074,0.9171246886253357,0.9972336292266846\n",
      "For range 0.4 to 0.6  -  146 pairs\n",
      "0.13459418341517448,0.9181327819824219,0.9896990805864334\n",
      "For range 0.6 to 0.8  -  89 pairs\n",
      "0.0458090677857399,0.36094900965690613,0.9177894592285156\n",
      "For range 0.8 to 1.01  -  48 pairs\n",
      "0.02807043818756938,0.058897823095321655,0.10355405882000923\n"
     ]
    }
   ],
   "source": [
    "result_analysis_by_range(pd_misinfo_ud, nn_sim_misinfo_ud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "530dc646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For range 0.0 to 0.2  -  258 pairs\n",
      "0.9988691210746765,0.9996564388275146,0.9999011904001236\n",
      "For range 0.2 to 0.4  -  125 pairs\n",
      "0.9991981983184814,0.9997649192810059,0.9999457001686096\n",
      "For range 0.4 to 0.6  -  146 pairs\n",
      "0.9989419877529144,0.9997016787528992,0.9999076128005981\n",
      "For range 0.6 to 0.8  -  89 pairs\n",
      "0.9989882707595825,0.9996993541717529,0.9998793005943298\n",
      "For range 0.8 to 1.01  -  48 pairs\n",
      "0.9991359114646912,0.999737948179245,0.9998822808265686\n"
     ]
    }
   ],
   "source": [
    "result_analysis_by_range(pd_misinfo_ud, novel_sim_misinfo_ud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c89d41f",
   "metadata": {},
   "source": [
    "#### Results: nonmisinfo to nonmisinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a9e0b78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For range 0.0 to 0.2  -  7750 pairs\n",
      "0.9217846244573593,0.9540671706199646,0.9731397479772568\n",
      "No pairs for range 0.2 to 0.4\n",
      "No pairs for range 0.4 to 0.6\n",
      "No pairs for range 0.6 to 0.8\n",
      "No pairs for range 0.8 to 1.01\n"
     ]
    }
   ],
   "source": [
    "result_analysis_by_range(pd_nonmisinfo_ud, w2v_sim_nonmisinfo_ud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e9382b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For range 0.0 to 0.2  -  7750 pairs\n",
      "0.976519450545311,0.9969258010387421,0.9995447993278503\n",
      "No pairs for range 0.2 to 0.4\n",
      "No pairs for range 0.4 to 0.6\n",
      "No pairs for range 0.6 to 0.8\n",
      "No pairs for range 0.8 to 1.01\n"
     ]
    }
   ],
   "source": [
    "result_analysis_by_range(pd_nonmisinfo_ud, nn_sim_nonmisinfo_ud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31816cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For range 0.0 to 0.2  -  7750 pairs\n",
      "0.9990141540765762,0.9996667802333832,0.9999121278524399\n",
      "No pairs for range 0.2 to 0.4\n",
      "No pairs for range 0.4 to 0.6\n",
      "No pairs for range 0.6 to 0.8\n",
      "No pairs for range 0.8 to 1.01\n"
     ]
    }
   ],
   "source": [
    "result_analysis_by_range(pd_nonmisinfo_ud, novel_sim_nonmisinfo_ud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada1d0be",
   "metadata": {},
   "source": [
    "#### Results: misinfo to nonmisinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "416668c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For range 0.0 to 0.2  -  1125 pairs\n",
      "0.9460095763206482,0.9685550332069397,0.9811440110206604\n",
      "For range 0.2 to 0.4  -  1625 pairs\n",
      "0.9324469566345215,0.9578205943107605,0.9724388122558594\n",
      "For range 0.4 to 0.6  -  125 pairs\n",
      "0.9456844329833984,0.9709511399269104,0.9843785762786865\n",
      "For range 0.6 to 0.8  -  1125 pairs\n",
      "0.9349206686019897,0.960141122341156,0.9735148549079895\n",
      "For range 0.8 to 1.01  -  625 pairs\n",
      "0.9469743967056274,0.9641695618629456,0.9771322011947632\n"
     ]
    }
   ],
   "source": [
    "result_analysis_by_range(pd_both_ud, w2v_sim_both_ud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "728f3611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For range 0.0 to 0.2  -  1125 pairs\n",
      "0.991191565990448,0.9977689385414124,0.9992472529411316\n",
      "For range 0.2 to 0.4  -  1625 pairs\n",
      "0.6346403360366821,0.9918893575668335,0.9986367225646973\n",
      "For range 0.4 to 0.6  -  125 pairs\n",
      "0.5360397696495056,0.5589452981948853,0.6129161715507507\n",
      "For range 0.6 to 0.8  -  1125 pairs\n",
      "0.08983024209737778,0.9198633432388306,0.9897669553756714\n",
      "For range 0.8 to 1.01  -  625 pairs\n",
      "0.008286419324576855,0.052968502044677734,0.3504315912723541\n"
     ]
    }
   ],
   "source": [
    "result_analysis_by_range(pd_both_ud, nn_sim_both_ud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08515ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For range 0.0 to 0.2  -  1125 pairs\n",
      "0.9979409575462341,0.9995355010032654,0.9998689889907837\n",
      "For range 0.2 to 0.4  -  1625 pairs\n",
      "0.9990849494934082,0.9997081160545349,0.9999186396598816\n",
      "For range 0.4 to 0.6  -  125 pairs\n",
      "0.9994762539863586,0.9998292326927185,0.9999659657478333\n",
      "For range 0.6 to 0.8  -  1125 pairs\n",
      "0.9990374445915222,0.9996687173843384,0.999912440776825\n",
      "For range 0.8 to 1.01  -  625 pairs\n",
      "0.999190628528595,0.9997054934501648,0.9999157190322876\n"
     ]
    }
   ],
   "source": [
    "result_analysis_by_range(pd_both_ud, novel_sim_both_ud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2996ecac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2120,)\n",
      "768\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11c1e1810b247a996face7d7f307c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9239965677261353 1.000000238418579\n"
     ]
    }
   ],
   "source": [
    "def chunk_to_chunk(df_video, df_channel, chunk_embeddings):\n",
    "    num_channels = len(df_channel)\n",
    "    channel_embeddings = [[] for _ in range(num_channels)]\n",
    "    \n",
    "    for index, row in df_channel.iterrows():\n",
    "        videos = row['video_ids'].split(',')\n",
    "        video_i = df_video.index[df_video[\"video_id\"].isin(videos)]  \n",
    "        chunk = chunk_embeddings[video_i]\n",
    "        for elem in chunk:\n",
    "            channel_embeddings[index] += elem\n",
    "\n",
    "    return np.array(channel_embeddings, dtype=object)\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "t = 0.75\n",
    "def chunk_cosine_similarities(mat):\n",
    "    cos_sim = np.zeros((mat.shape[0], mat.shape[0]))    \n",
    "    for i in trange(mat.shape[0]):\n",
    "        for j in range(mat.shape[0]):\n",
    "            cos_mat = cosine_similarity(mat[i], mat[j])\n",
    "            cos_mat = cos_mat.flatten()\n",
    "            cos_mat_len = len(cos_mat)\n",
    "            m = cos_mat[cos_mat > t]\n",
    "            cos_mat_max = len(m) \n",
    "            cos_mat_min = len(cos_mat[cos_mat <= t])\n",
    "\n",
    "            # cos_mat_max = (cos_mat_len - cos_mat_max) / (0.5 * (cos_mat_max + cos_mat_len))\n",
    "            # cos_mat_min = (cos_mat_len - cos_mat_min) / (0.5 * (cos_mat_min + cos_mat_len))\n",
    "            if cos_mat_max <= cos_mat_min:\n",
    "                cos_sim[i, j] = 0.0\n",
    "            else:\n",
    "                cos_sim[i, j] = m.min()\n",
    "\n",
    "            # if len(cos_mat) == 0:\n",
    "            #     cos_sim[i, j] = 0.0\n",
    "            # else:\n",
    "            #     cos_sim[i, j] = np.min(cos_mat)\n",
    "    return cos_sim\n",
    "\n",
    "chunk_embeddings = np.load(join(root_path, 'bi2_embedding.npy'), allow_pickle=True)\n",
    "print(chunk_embeddings.shape)\n",
    "print(len(chunk_embeddings[0][0]))\n",
    "\n",
    "chunked_channel_emb = chunk_to_chunk(df_video1, df_channel, chunk_embeddings)\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "chunk_cos_sim = chunk_cosine_similarities(chunked_channel_emb)\n",
    "print(chunk_cos_sim.min(), chunk_cos_sim.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48f094a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chunk_sim_all = chunk_cos_sim[filtered_indices, :][:, filtered_indices]\n",
    "chunk_sim_misinfo = chunk_cos_sim[filtered_misinfo_indices, :][:, filtered_misinfo_indices]\n",
    "chunk_sim_nonmisinfo = chunk_cos_sim[filtered_nonmisinfo_indices, :][:, filtered_nonmisinfo_indices]\n",
    "chunk_sim_both = chunk_cos_sim[filtered_misinfo_indices, :][:, filtered_nonmisinfo_indices]\n",
    "\n",
    "chunk_sim_all_ud = chunk_sim_all[ind_all]\n",
    "chunk_sim_all_minsinfo_ud = chunk_sim_misinfo[ind_misinfo]\n",
    "chunk_sim_all_nonmisinfo_ud = chunk_cos_sim[ind_nonmisinfo]\n",
    "chunk_sim_both_ud = chunk_sim_both.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41a51030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For range 0.0 to 0.2  -  9133 pairs\n",
      "0.9770883917808533,0.9831773638725281,0.987862229347229\n",
      "For range 0.2 to 0.4  -  1750 pairs\n",
      "0.976630374789238,0.983600378036499,0.9880243092775345\n",
      "For range 0.4 to 0.6  -  271 pairs\n",
      "0.9796615242958069,0.9856457710266113,0.989536464214325\n",
      "For range 0.6 to 0.8  -  1214 pairs\n",
      "0.9799032807350159,0.9858368933200836,0.9902356266975403\n",
      "For range 0.8 to 1.01  -  673 pairs\n",
      "0.9770849943161011,0.9861478805541992,0.9899656772613525\n"
     ]
    }
   ],
   "source": [
    "result_analysis_by_range(pd_all_ud, chunk_sim_all_ud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf0a465b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For range 0.0 to 0.2  -  258 pairs\n",
      "0.9717417508363724,0.9802733957767487,0.9864931106567383\n",
      "For range 0.2 to 0.4  -  125 pairs\n",
      "0.9769965410232544,0.9847503900527954,0.9900976419448853\n",
      "For range 0.4 to 0.6  -  146 pairs\n",
      "0.9770472943782806,0.9829241037368774,0.9885358661413193\n",
      "For range 0.6 to 0.8  -  89 pairs\n",
      "0.9706945419311523,0.9820359945297241,0.9884343147277832\n",
      "For range 0.8 to 1.01  -  48 pairs\n",
      "0.9776507616043091,0.9848083555698395,0.98786860704422\n"
     ]
    }
   ],
   "source": [
    "result_analysis_by_range(pd_misinfo_ud, chunk_sim_all_minsinfo_ud)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "94997fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For range 0.0 to 0.2  -  7750 pairs\n",
      "0.9828147441148758,0.9888578355312347,0.9932411760091782\n",
      "No pairs for range 0.2 to 0.4\n",
      "No pairs for range 0.4 to 0.6\n",
      "No pairs for range 0.6 to 0.8\n",
      "No pairs for range 0.8 to 1.01\n"
     ]
    }
   ],
   "source": [
    "result_analysis_by_range(pd_nonmisinfo_ud, chunk_sim_all_nonmisinfo_ud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44054a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For range 0.0 to 0.2  -  1125 pairs\n",
      "0.9719547033309937,0.9777891635894775,0.982799232006073\n",
      "For range 0.2 to 0.4  -  1625 pairs\n",
      "0.9765671491622925,0.9835426807403564,0.9878278970718384\n",
      "For range 0.4 to 0.6  -  125 pairs\n",
      "0.9843184947967529,0.9873199462890625,0.9904522895812988\n",
      "For range 0.6 to 0.8  -  1125 pairs\n",
      "0.9804402589797974,0.9860204458236694,0.990294337272644\n",
      "For range 0.8 to 1.01  -  625 pairs\n",
      "0.9769406914710999,0.9863744974136353,0.9900457859039307\n"
     ]
    }
   ],
   "source": [
    "result_analysis_by_range(pd_both_ud, chunk_sim_both_ud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da9d6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
