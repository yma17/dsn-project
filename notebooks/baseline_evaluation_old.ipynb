{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "047e08b0-7afd-4dc5-bcd6-89a4a93e4d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno -2] Name or\n",
      "[nltk_data]     service not known>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [Errno -2] Name or\n",
      "[nltk_data]     service not known>\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import gensim\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import sklearn.preprocessing as pp\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "join = os.path.join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7c1abe",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f63f906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.3\n"
     ]
    }
   ],
   "source": [
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9636dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"./../data/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75a7bd62-4257-4c4a-9783-684025cfaf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "\n",
    "video1_csv = \"baseline1_final.csv\"\n",
    "comment1_csv = \"baseline1_comment_final.csv\"\n",
    "\n",
    "df_video1 = pd.read_csv(join(root_path, video1_csv), sep='\\t')\n",
    "df_comment1 = pd.read_csv(join(root_path, comment1_csv), sep='\\t')\n",
    "\n",
    "video2_csv = \"baseline2_final.csv\"\n",
    "comment2_csv = \"baseline2_comment_final.csv\"\n",
    "\n",
    "df_video2 = pd.read_csv(join(root_path, video2_csv), sep='\\t')\n",
    "df_comment2 = pd.read_csv(join(root_path, comment2_csv), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3a7a541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it happened outside waco texas a heavily armed...</td>\n",
       "      <td>the shadow of waco  retro report  the new york...</td>\n",
       "      <td>0</td>\n",
       "      <td>hOW9AjskoOo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thanks for coming its nice to see a good turno...</td>\n",
       "      <td>former abortionist dr levatino destroys procho...</td>\n",
       "      <td>0</td>\n",
       "      <td>dIRcw45n9RU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tonight  i donald john trump do solemnly swear...</td>\n",
       "      <td>trumps road to the white house full film  fron...</td>\n",
       "      <td>0</td>\n",
       "      <td>SMwXKl0odq8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this week on buzzfeed unsolved we discuss the...</td>\n",
       "      <td>the strange disappearance of db cooper</td>\n",
       "      <td>0</td>\n",
       "      <td>oHSehKtDyoI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im mason noise im 22 and im from birmingham wh...</td>\n",
       "      <td>shockingly offensive auditions have simon cowe...</td>\n",
       "      <td>0</td>\n",
       "      <td>N9COy7O7K-U</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             caption  \\\n",
       "0  it happened outside waco texas a heavily armed...   \n",
       "1  thanks for coming its nice to see a good turno...   \n",
       "2  tonight  i donald john trump do solemnly swear...   \n",
       "3   this week on buzzfeed unsolved we discuss the...   \n",
       "4  im mason noise im 22 and im from birmingham wh...   \n",
       "\n",
       "                                               title  label     video_id  \n",
       "0  the shadow of waco  retro report  the new york...      0  hOW9AjskoOo  \n",
       "1  former abortionist dr levatino destroys procho...      0  dIRcw45n9RU  \n",
       "2  trumps road to the white house full film  fron...      0  SMwXKl0odq8  \n",
       "3             the strange disappearance of db cooper      0  oHSehKtDyoI  \n",
       "4  shockingly offensive auditions have simon cowe...      0  N9COy7O7K-U  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_video1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29a13e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hOW9AjskoOo</td>\n",
       "      <td>im sry for the kids but the rest they became w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hOW9AjskoOo</td>\n",
       "      <td>this testifies to the power of automatic weapo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hOW9AjskoOo</td>\n",
       "      <td>these days they will just drone strike a build...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hOW9AjskoOo</td>\n",
       "      <td>935 crazy how this phrase will likely never be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hOW9AjskoOo</td>\n",
       "      <td>no true christian would burn their kids</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                            comment\n",
       "0  hOW9AjskoOo  im sry for the kids but the rest they became w...\n",
       "1  hOW9AjskoOo  this testifies to the power of automatic weapo...\n",
       "2  hOW9AjskoOo  these days they will just drone strike a build...\n",
       "3  hOW9AjskoOo  935 crazy how this phrase will likely never be...\n",
       "4  hOW9AjskoOo            no true christian would burn their kids"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comment1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2d95c7c-a470-44a9-b336-c60efec1805c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2120, 4)\n",
      "(177514, 2)\n",
      "(80, 4)\n",
      "(111526, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_video1.shape)\n",
    "print(df_comment1.shape)\n",
    "print(df_video2.shape)\n",
    "print(df_comment2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cd6bfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word2vec\n",
    "word2vec_300 = \"GoogleNews-vectors-negative300.bin\"\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(join(root_path, word2vec_300), binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b059504f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7a9f053-3140-458f-ae38-adaa97e25fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load glove\n",
    "glove_100d = \"glove.6B.100d.txt\"\n",
    "glove100d_embeddings_dict = {}\n",
    "f = open(os.path.join(root_path, glove_100d),'r', errors = 'ignore', encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = ''.join(values[:-100])\n",
    "    coefs = np.asarray(values[-100:], dtype='float32')\n",
    "    glove100d_embeddings_dict[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d41b7b6-90ac-43ad-b228-ea668c95b0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "print(len(glove100d_embeddings_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "80cdf8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>prove it see its back to spot chemtrails just ...</td>\n",
       "      <td>chemtrails exposed in new zealandthe land of t...</td>\n",
       "      <td>1</td>\n",
       "      <td>7Ptv-Z7goZ8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               caption  \\\n",
       "899  prove it see its back to spot chemtrails just ...   \n",
       "\n",
       "                                                 title  label     video_id  \n",
       "899  chemtrails exposed in new zealandthe land of t...      1  7Ptv-Z7goZ8  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_video1[df_video1[\"video_id\"] == \"7Ptv-Z7goZ8\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f82dcbc",
   "metadata": {},
   "source": [
    "### Captions -> word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb84c7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "captions1_list = df_video1[\"caption\"].to_list()\n",
    "video1_list = df_video1[\"video_id\"].to_list()\n",
    "captions2_list = df_video2[\"caption\"].to_list()\n",
    "video2_list = df_video2[\"video_id\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2c4ee23-ccc1-4614-ac02-9dfa8156947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(word2vec_model, doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    doc = [word for word in doc if word in word2vec_model.vocab]\n",
    "    return np.mean(word2vec_model[doc], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abf10cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our earlier preprocessing was done when we were dealing only with word vectors\n",
    "# Here, we need each document to remain a document \n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    doc = word_tokenize(text)\n",
    "    doc = [word for word in doc if word.isalpha()] \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91a1f38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that will help us drop documents that have no word vectors in word2vec\n",
    "def has_vector_representation(word2vec_model, doc):\n",
    "    \"\"\"check if at least one word of the document is in the\n",
    "    word2vec dictionary\"\"\"\n",
    "    return not all(word not in word2vec_model.vocab for word in doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83429f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out documents\n",
    "def filter_docs(corpus, texts, video_ids, condition_on_doc):\n",
    "    \"\"\"\n",
    "    Filter corpus and texts given the function condition_on_doc which takes a doc. The document doc is kept if condition_on_doc(doc) is true.\n",
    "    \"\"\"\n",
    "    number_of_docs = len(corpus)\n",
    "\n",
    "    ret_texts, ret_videos = [], []\n",
    "    if texts is not None:\n",
    "        for (text, doc, video_id) in zip(texts, corpus, video_ids):\n",
    "            if condition_on_doc(doc):\n",
    "                ret_texts.append(text)\n",
    "                ret_videos.append(video_id)\n",
    "\n",
    "    corpus = [doc for doc in corpus if condition_on_doc(doc)]\n",
    "\n",
    "    print(\"{} docs removed\".format(number_of_docs - len(corpus)))\n",
    "\n",
    "    return (corpus, ret_texts, ret_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f4c67dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def captions_to_word2vec(caption_list, video_list, model):\n",
    "    # Preprocess the corpus\n",
    "    corpus = [preprocess(title) for title in caption_list]\n",
    "\n",
    "    # Remove docs that don't include any words in W2V's vocab\n",
    "    corpus, titles_list, video_list = filter_docs(corpus, caption_list, video_list, lambda doc: has_vector_representation(model, doc))\n",
    "\n",
    "    # Filter out any empty docs\n",
    "    corpus, titles_list, video_list = filter_docs(corpus, caption_list, video_list, lambda doc: (len(doc) != 0))\n",
    "    x = []\n",
    "    for doc in corpus: # append the vector for each document\n",
    "        x.append(document_vector(model, doc))\n",
    "\n",
    "    X = np.array(x) # list to array\n",
    "    \n",
    "    return X, video_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e05cbc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 docs removed\n",
      "0 docs removed\n"
     ]
    }
   ],
   "source": [
    "captions1_X, cap_w2v_videos = captions_to_word2vec(captions1_list, video1_list, word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4a445f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2120, 300)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions1_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d06643d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hOW9AjskoOo', 'dIRcw45n9RU', 'SMwXKl0odq8', 'oHSehKtDyoI', 'N9COy7O7K-U']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(cap_w2v_videos))\n",
    "cap_w2v_videos[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b97f527e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 docs removed\n",
      "0 docs removed\n"
     ]
    }
   ],
   "source": [
    "captions2_X, cap2_w2v_videos = captions_to_word2vec(captions2_list, video2_list, word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06b46010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 300)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions2_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bde4260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0jmhj-vnl5E', '1cWvGnF6_dw', '3DAI3c9wE0Q', '4G1LTpm1pkw', '4tD0w86MTuA']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(cap2_w2v_videos))\n",
    "cap2_w2v_videos[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01514135",
   "metadata": {},
   "source": [
    "### Captions -> glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8baa2e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define captions as numpy array (paper 1 + paper 2, 2120 + 80)\n",
    "captions1_texts_concat = np.empty([2200, 1], dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ee24878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get captions as numpy array \n",
    "# length of captions from paper 1 is 2120\n",
    "prev_video_id = ''\n",
    "cur_i = 0\n",
    "captions1_texts_concat[0] = ''\n",
    "for index, row in df_video1.iterrows():\n",
    "    if row['video_id'] != prev_video_id and prev_video_id: # new video_id\n",
    "        # next video_id index\n",
    "        cur_i += 1\n",
    "        captions1_texts_concat[cur_i] =  row['caption']\n",
    "    # else, same video\n",
    "    # concat caption for that video_id  \n",
    "    else:\n",
    "        captions1_texts_concat[cur_i] +=  row['caption']\n",
    "        prev_video_id = row['video_id']\n",
    "for index, row in df_video2.iterrows():\n",
    "    if row['video_id'] != prev_video_id and prev_video_id: # new video_id\n",
    "        # next video_id index\n",
    "        cur_i += 1\n",
    "        captions1_texts_concat[cur_i] =  row['caption']\n",
    "    # else, same video\n",
    "    # concat caption for that video_id  \n",
    "    else:\n",
    "        captions1_texts_concat[cur_i] +=  row['caption']\n",
    "        prev_video_id = row['video_id']\n",
    "#normalized_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fa6aa47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "X_captions1 = np.zeros((2200, 100))\n",
    "Y_captions1 = np.zeros((2200,))\n",
    "\n",
    "df_video = pd.concat([df_video1, df_video2], axis=0)\n",
    "df_video.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for i, caption in enumerate(captions1_texts_concat):\n",
    "    #try:\n",
    "    if caption[0] and len(caption[0]) > 1: # ['o'] -- skip when cv.fit_transform(caption) fails\n",
    "        cv_fit_caption=cv.fit_transform(caption)\n",
    "        caption_features = cv.get_feature_names_out()\n",
    "        caption_feature_weights = cv_fit_caption.toarray()\n",
    "\n",
    "        total_caption_weights = sum(caption_feature_weights[0])\n",
    "        sum_embeddings = None\n",
    "        for j, weight in enumerate(caption_feature_weights[0]):\n",
    "            try:\n",
    "                # check if key in embedding dictionary\n",
    "                if caption_features[j] in glove100d_embeddings_dict:\n",
    "                    if j == 0: \n",
    "                        sum_embeddings = weight*glove100d_embeddings_dict[caption_features[j]]\n",
    "                    else:\n",
    "                        sum_embeddings += weight*glove100d_embeddings_dict[caption_features[j]]\n",
    "            except:\n",
    "                pass\n",
    "                #print(caption_features[j])\n",
    "\n",
    "        # calculate caption embedding\n",
    "        if sum_embeddings is not None:\n",
    "            caption_embedding = np.divide(sum_embeddings, total_caption_weights)\n",
    "\n",
    "            # append to captions dataset\n",
    "            X_captions1[i] = caption_embedding\n",
    "            \n",
    "            # append label for captions dataset\n",
    "            Y_captions1[i] = 1 if df_video.iloc[i]['label'] == 1 else 0 # 1 is misinfo, 0 is non-misinfo\n",
    "            \n",
    "         \n",
    "\n",
    "        \n",
    "#     except:\n",
    "#         print('Error')\n",
    "#         cv_fit_caption=cv.fit_transform(caption)\n",
    "#         caption_features = cv.get_feature_names_out()\n",
    "#         caption_feature_weights = cv_fit_caption.toarray()\n",
    "        \n",
    "#         #print(caption_feature_weights)\n",
    "#         error += 1\n",
    "#         if error == 1:\n",
    "#             break\n",
    "#         pass\n",
    "    #print(sum_embeddings)\n",
    "    # if i == 2:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7bf4a56b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zero_ind = np.where(~np.all(X_captions1 == 0, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a332ae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_1b = []\n",
    "cand_videos = cap_w2v_videos + cap2_w2v_videos\n",
    "for i, v in enumerate(cand_videos):\n",
    "    if i not in zero_ind[0]:\n",
    "        video_1b += [v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a3fb5a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_captions1 = X_captions1[zero_ind]\n",
    "Y_captions1 = Y_captions1[zero_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2a13e71c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_captions1[2199]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "872dc857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_captions1[2199]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3e17a8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2122, 100)\n",
      "(2122,)\n",
      "2122\n"
     ]
    }
   ],
   "source": [
    "print(X_captions1.shape)\n",
    "print(Y_captions1.shape)\n",
    "print(len(video_1b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574adb89",
   "metadata": {},
   "source": [
    "### Titles, comments -> tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7c8ab630",
   "metadata": {},
   "outputs": [],
   "source": [
    "title1_list = df_video1[\"title\"].to_list()\n",
    "video1_list = df_video1[\"video_id\"].to_list()\n",
    "title2_list = df_video2[\"title\"].to_list()\n",
    "video2_list = df_video2[\"video_id\"].to_list()\n",
    "\n",
    "title_list = title1_list + title2_list\n",
    "video_list = video1_list + video2_list\n",
    "\n",
    "df_comment = pd.concat([df_comment1, df_comment2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "61bf9ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corpus(titles, videos, comments):\n",
    "    \"\"\"Simply concatenate titles and comments for each video into one long string\"\"\"\n",
    "    corpus = []\n",
    "    for (title, video_id) in zip(titles, videos):\n",
    "        comments_v = comments[comments[\"video_id\"] == video_id]\n",
    "        corpus_elem = [title] + comments_v[\"comment\"].to_list()\n",
    "        corpus_elem = [str(x) for x in corpus_elem]\n",
    "        corpus_elem = ' '.join(corpus_elem)\n",
    "        corpus += [corpus_elem]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "00e5f939",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = create_corpus(title_list, video_list, df_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cff50d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tf-idf\n",
    "vectorizer = TfidfVectorizer()\n",
    "tc_X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fa7fee00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200, 185568)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30261d09",
   "metadata": {},
   "source": [
    "### Baseline 1 models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14dbd3e",
   "metadata": {},
   "source": [
    "#### Word2vec SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35d6382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(model_name, y_test, y_pred):\n",
    "    print(model_name, \"results:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"F1 score:\", f1_score(y_test, y_pred))\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"Cross entropy loss:\", log_loss(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "b3458f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(536, 300) (135, 300) (536,) (135,)\n"
     ]
    }
   ],
   "source": [
    "X = np.vstack([captions1_X, captions2_X])\n",
    "y = np.hstack([df_video1[\"label\"].to_numpy(), df_video2[\"label\"].to_numpy()])\n",
    "\n",
    "X = X[1529:, :]\n",
    "y = y[1529:]\n",
    "\n",
    "y[y == -1] = 0  # make two class\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "d14de59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: Counter({0: 487, 1: 49})\n",
      "After SMOTE: Counter({0: 243, 1: 243})\n"
     ]
    }
   ],
   "source": [
    "# Use SMOTE to oversample minority class for training\n",
    "print(\"Before SMOTE:\", Counter(y_train))\n",
    "over = SMOTE(sampling_strategy=0.5)\n",
    "under = RandomUnderSampler(sampling_strategy=1.0)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "print(\"After SMOTE:\", Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "b3924704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svc', SVC(gamma='auto'))])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train SVC model (word2vec)\n",
    "clf_1a = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf_1a.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "cc02615b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline 1 word2vec SVC results:\n",
      "Accuracy: 0.9259259259259259\n",
      "F1 score: 0.5833333333333334\n",
      "Confusion matrix:\n",
      "[[118   6]\n",
      " [  4   7]]\n",
      "Cross entropy loss: 2.55846341876806\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_1a.predict(X_test)\n",
    "print_results(\"Baseline 1 word2vec SVC\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27a731fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos_by_result(video_list, y_test, y_pred):\n",
    "    t, fp, fn = [], [], []\n",
    "    for (video_id, gt, pred) in zip(video_list, y_test, y_pred):\n",
    "        if gt == pred:\n",
    "            t += [video_id]\n",
    "        elif gt == 0 and pred == 1:\n",
    "            fp += [video_id]\n",
    "        else:  # gt == 1 and pred == 0\n",
    "            fn += [video_id]\n",
    "    return t, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f86eddd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2080 105 15\n"
     ]
    }
   ],
   "source": [
    "videos = cap_w2v_videos + cap2_w2v_videos\n",
    "y_pred = clf_1a.predict(X)\n",
    "t_1a, fp_1a, fn_1a = get_videos_by_result(videos, y, y_pred)\n",
    "print(len(t_1a), len(fp_1a), len(fn_1a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab376023",
   "metadata": {},
   "source": [
    "#### Glove SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c3e726f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1697, 100) (425, 100) (1697,) (425,)\n"
     ]
    }
   ],
   "source": [
    "X = X_captions1\n",
    "y = Y_captions1\n",
    "\n",
    "y[y == -1] = 0  # make two class\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ef02a9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: Counter({0.0: 1478, 1.0: 219})\n",
      "After SMOTE: Counter({0.0: 1108, 1.0: 1108})\n"
     ]
    }
   ],
   "source": [
    "# Use SMOTE to oversample minority class for training\n",
    "print(\"Before SMOTE:\", Counter(y_train))\n",
    "over = SMOTE(sampling_strategy=0.75)\n",
    "under = RandomUnderSampler(sampling_strategy=1.0)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "print(\"After SMOTE:\", Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "01b158f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svc', SVC(gamma='auto'))])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train SVC model (word2vec)\n",
    "clf_1b = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf_1b.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f3aa18ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline 1 glove SVC results:\n",
      "Accuracy: 0.88\n",
      "F1 score: 0.5785123966942148\n",
      "Confusion matrix:\n",
      "[[339  32]\n",
      " [ 19  35]]\n",
      "Cross entropy loss: 4.144713372372262\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_1b.predict(X_test)\n",
    "print_results(\"Baseline 1 glove SVC\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a46d803a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960 133 29\n"
     ]
    }
   ],
   "source": [
    "videos = video_1b\n",
    "y_pred = clf_1b.predict(X)\n",
    "t_1b, fp_1b, fn_1b = get_videos_by_result(videos, y, y_pred)\n",
    "print(len(t_1b), len(fp_1b), len(fn_1b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536560fa",
   "metadata": {},
   "source": [
    "### Baseline 2 models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a6d11a",
   "metadata": {},
   "source": [
    "#### tf-idf SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "e38a6ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(536, 185568) (135, 185568) (536,) (135,)\n"
     ]
    }
   ],
   "source": [
    "X = tc_X\n",
    "y = np.hstack([df_video1[\"label\"].to_numpy(), df_video2[\"label\"].to_numpy()])\n",
    "\n",
    "X = X[1529:, :]\n",
    "y = y[1529:]\n",
    "\n",
    "y[y == -1] = 0  # make two class\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "c379040b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: Counter({0: 491, 1: 45})\n",
      "After SMOTE: Counter({0: 368, 1: 368})\n"
     ]
    }
   ],
   "source": [
    "# Use SMOTE to oversample minority class for training\n",
    "print(\"Before SMOTE:\", Counter(y_train))\n",
    "over = SMOTE(sampling_strategy=0.75)\n",
    "under = RandomUnderSampler(sampling_strategy=1.0)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "print(\"After SMOTE:\", Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "1a605c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]*\n",
      "optimization finished, #iter = 368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(gamma='auto', verbose=1)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj = -735.950126, rho = -0.000638\n",
      "nSV = 736, nBSV = 736\n",
      "Total nSV = 736\n"
     ]
    }
   ],
   "source": [
    "# Train SVC model\n",
    "clf_2a = SVC(gamma='auto', verbose=1)\n",
    "clf_2a.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "8894ec06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline 2 tf-idf SVC results:\n",
      "Accuracy: 0.42962962962962964\n",
      "F1 score: 0.26666666666666666\n",
      "Confusion matrix:\n",
      "[[44 76]\n",
      " [ 1 14]]\n",
      "Cross entropy loss: 19.70034482824309\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_2a.predict(X_test)\n",
    "print_results(\"Baseline 2 tf-idf SVC\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3923ba30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1223 901 76\n"
     ]
    }
   ],
   "source": [
    "videos = cap_w2v_videos + cap2_w2v_videos\n",
    "y_pred = clf_2a.predict(X)\n",
    "t_2a, fp_2a, fn_2a = get_videos_by_result(videos, y, y_pred)\n",
    "print(len(t_2a), len(fp_2a), len(fn_2a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205ff5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### tf-idf RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "eb081bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1760, 185568) (440, 185568) (1760,) (440,)\n"
     ]
    }
   ],
   "source": [
    "X = tc_X\n",
    "y = np.hstack([df_video1[\"label\"].to_numpy(), df_video2[\"label\"].to_numpy()])\n",
    "\n",
    "y[y == -1] = 0  # make two class\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2a1692a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: Counter({0: 1533, 1: 227})\n",
      "After SMOTE: Counter({0: 1149, 1: 1149})\n"
     ]
    }
   ],
   "source": [
    "# Use SMOTE to oversample minority class for training\n",
    "print(\"Before SMOTE:\", Counter(y_train))\n",
    "over = SMOTE(sampling_strategy=0.75)\n",
    "under = RandomUnderSampler(sampling_strategy=1.0)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "print(\"After SMOTE:\", Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "666f6fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=800, n_jobs=-1)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train RandomForest model\n",
    "clf_2b = RandomForestClassifier(n_estimators=800, n_jobs=-1)\n",
    "clf_2b.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "05d5878d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline 2 tf-idf RF results:\n",
      "Accuracy: 0.8886363636363637\n",
      "F1 score: 0.36363636363636365\n",
      "Confusion matrix:\n",
      "[[377  10]\n",
      " [ 39  14]]\n",
      "Cross entropy loss: 3.846381907556649\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_2b.predict(X_test)\n",
    "print_results(\"Baseline 2 tf-idf RF\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "be31e990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2144 17 39\n"
     ]
    }
   ],
   "source": [
    "videos = cap_w2v_videos + cap2_w2v_videos\n",
    "y_pred = clf_2b.predict(X)\n",
    "t_2b, fp_2b, fn_2b = get_videos_by_result(videos, y, y_pred)\n",
    "print(len(t_2b), len(fp_2b), len(fn_2b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6b4c8d",
   "metadata": {},
   "source": [
    "### Save all predictions to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "db89b679",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = {\"video_id\": [], \"svc_tfidf\": [], \"svc_w2v\": [], \"svc_glove\": [], \"rf_tfidf\": [], \"3_label\": [], \"2_label\":[]}\n",
    "y = np.hstack([df_video1[\"label\"].to_numpy(), df_video2[\"label\"].to_numpy()])\n",
    "z = y.copy()\n",
    "z[z == -1] = 0  # make two class\n",
    "videos = cap_w2v_videos + cap2_w2v_videos\n",
    "\n",
    "for (video, label1, label2) in zip(videos, y, z):\n",
    "    res_dict[\"video_id\"] += [video]\n",
    "    \n",
    "    # svc_tfidf (2a)\n",
    "    if video in t_2a:\n",
    "        res_dict[\"svc_tfidf\"] += [\"T\"]\n",
    "    elif video in fp_2a:\n",
    "        res_dict[\"svc_tfidf\"] += [\"FP\"]\n",
    "    else:\n",
    "        res_dict[\"svc_tfidf\"] += [\"FN\"]\n",
    "    \n",
    "    # svc_w2v (1a)\n",
    "    if video in t_1a:\n",
    "        res_dict[\"svc_w2v\"] += [\"T\"]\n",
    "    elif video in fp_1a:\n",
    "        res_dict[\"svc_w2v\"] += [\"FP\"]\n",
    "    else:\n",
    "        res_dict[\"svc_w2v\"] += [\"FN\"]\n",
    "    \n",
    "    # svc_glove (note that there were some embedding failures) (1b)\n",
    "    if video in t_1b:\n",
    "        res_dict[\"svc_glove\"] += [\"T\"]\n",
    "    elif video in fp_1b:\n",
    "        res_dict[\"svc_glove\"] += [\"FP\"]\n",
    "    elif video in fn_1b:\n",
    "        res_dict[\"svc_glove\"] += [\"FN\"]\n",
    "    else:\n",
    "        res_dict[\"svc_glove\"] += [\"N/A\"]  # embedding failure\n",
    "    \n",
    "    # rf_tfidf (2b)\n",
    "    if video in t_2b:\n",
    "        res_dict[\"rf_tfidf\"] += [\"T\"]\n",
    "    elif video in fp_2b:\n",
    "        res_dict[\"rf_tfidf\"] += [\"FP\"]\n",
    "    else:\n",
    "        res_dict[\"rf_tfidf\"] += [\"FN\"]\n",
    "    \n",
    "    res_dict[\"3_label\"] += [label1]\n",
    "    res_dict[\"2_label\"] += [label2]\n",
    "        \n",
    "pd.DataFrame(res_dict).to_csv('baseline_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e7f35e",
   "metadata": {},
   "source": [
    "### Calculating cosine similarity of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "09c130df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embedd = pd.read_csv('_embedd.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9bf954b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedd_videos = set(df_embedd['video_id'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "95897d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarities(mat):\n",
    "    col_normed_mat = pp.normalize(coo_matrix(mat.T).tocsc(), axis=0)\n",
    "    return col_normed_mat.T * col_normed_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a9a5f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_sim = cosine_similarities(tc_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f40fe8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_sim = cosine_similarities(np.vstack([captions1_X, captions2_X]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d43ac1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_sim = cosine_similarities(X_captions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e7d078db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200, 2200)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a737f143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2122, 2122)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fc5124",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_sim = tf_sim.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1232245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_sim = word2vec_sim.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a7d64c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99999976, 0.93542814, 0.962264  ],\n",
       "       [0.93542814, 0.99999976, 0.9643437 ],\n",
       "       [0.962264  , 0.9643437 , 1.0000001 ]], dtype=float32)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_sim[:3, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "108cd1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_sim[word2vec_sim < 0.0] = 0.0\n",
    "word2vec_sim[word2vec_sim > 1.0] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "06ed635d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.0)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_sim.max(), word2vec_sim.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bb712c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_sim = glove_sim.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "fbe3d08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.98440973, 0.98987664],\n",
       "       [0.98440973, 1.        , 0.9928833 ],\n",
       "       [0.98987664, 0.9928833 , 1.        ]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_sim[:3, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "dc76a63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_sim[glove_sim < 0.0] = 0.0\n",
    "glove_sim[glove_sim > 1.0] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9f0e7430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.36732266597963353)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_sim.max(), glove_sim.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3b0d6415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec match results:\n",
      "Accuracy: 0.5300657323576833\n",
      "F1 score: 0.6917487378154241\n",
      "Confusion matrix:\n",
      "[[   6711 1126448]\n",
      " [  10276 1275465]]\n",
      "Cross entropy loss: 16.23132695177747\n"
     ]
    }
   ],
   "source": [
    "# word2vec - compute precision, recall, F1-score\n",
    "\n",
    "word2vec_dict = {}\n",
    "videos = cap_w2v_videos + cap2_w2v_videos\n",
    "labels = np.hstack([df_video1[\"label\"].to_numpy(), df_video2[\"label\"].to_numpy()])\n",
    "\n",
    "y_test, y_pred = [], []\n",
    "for i, video1 in enumerate(videos):\n",
    "    for j, video2 in enumerate(videos):\n",
    "        if i <= j:\n",
    "            continue\n",
    "        if labels[i] == labels[j]:\n",
    "            y_test += [1]\n",
    "            y_pred += [1 if word2vec_sim[i][j] >= 0.5 else 0]\n",
    "        else:\n",
    "            y_test += [0]\n",
    "            y_pred += [0 if word2vec_sim[i][j] < 0.5 else 1]\n",
    "        \n",
    "# y_true, y_pred\n",
    "print_results(\"word2vec match\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9b584353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove match results:\n",
      "Accuracy: 0.7760143726773377\n",
      "F1 score: 0.8738266675844977\n",
      "Confusion matrix:\n",
      "[[    892  503885]\n",
      " [    168 1745436]]\n",
      "Cross entropy loss: 7.736368536410071\n"
     ]
    }
   ],
   "source": [
    "# glove - compute precision, recall, F1-score\n",
    "\n",
    "glove_dict = {}\n",
    "videos = video_1b\n",
    "labels = Y_captions1\n",
    "\n",
    "y_test, y_pred = [], []\n",
    "for i, video1 in enumerate(videos):\n",
    "    for j, video2 in enumerate(videos):\n",
    "        if i <= j:\n",
    "            continue\n",
    "        if labels[i] == labels[j]:\n",
    "            y_test += [1]\n",
    "            y_pred += [1 if glove_sim[i][j] >= 0.5 else 0]\n",
    "        else:\n",
    "            y_test += [0]\n",
    "            y_pred += [0 if glove_sim[i][j] < 0.5 else 1]\n",
    "        \n",
    "# y_true, y_pred\n",
    "print_results(\"glove match\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bd2f52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
